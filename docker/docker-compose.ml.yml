services:
  # Whisper transcription worker
  whisper-worker:
    build:
      context: ../python
      dockerfile: whisper-service/Dockerfile
    working_dir: /app
    command: ["sh", "-c", "cd /app/whisper-service && celery -A celery_app worker -Q ml.transcribe --pool=solo --loglevel=info --hostname=whisper@%h -O fair --without-mingle"]
    environment:
      - PYTHONPATH=/app
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_USER=ml
      - RABBITMQ_PASS=ml_password
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=bookmarkai
      - POSTGRES_PASSWORD=bookmarkai_password
      - POSTGRES_DB=bookmarkai_dev
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - S3_ENDPOINT=http://minio:9000
      - S3_ACCESS_KEY=minioadmin
      - S3_SECRET_KEY=minioadmin
      - S3_USE_PATH_STYLE=true
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://tempo:4318
      - LOG_LEVEL=INFO
    depends_on:
      rabbitmq:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ../python:/app
    networks:
      - bookmarkai-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "sh", "-c", "ps aux | grep -v grep | grep -q 'celery.*worker.*ml.transcribe' && echo 'healthy' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # LLM summarization worker
  llm-worker:
    build:
      context: ../python
      dockerfile: llm-service/Dockerfile
    working_dir: /app
    command: ["sh", "-c", "cd /app/llm-service && ./start_worker.sh"]
    environment:
      - PYTHONPATH=/app
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_USER=ml
      - RABBITMQ_PASS=ml_password
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=bookmarkai
      - POSTGRES_PASSWORD=bookmarkai_password
      - POSTGRES_DB=bookmarkai_dev
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://tempo:4318
      - LOG_LEVEL=INFO
    depends_on:
      rabbitmq:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ../python:/app
    networks:
      - bookmarkai-network
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 2G
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "sh", "-c", "ps aux | grep -v grep | grep -q 'celery.*worker.*ml.summarize' && echo 'healthy' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Vector embedding worker
  vector-worker:
    build:
      context: ../python
      dockerfile: vector-service/Dockerfile
    working_dir: /app
    command: ["sh", "-c", "cd /app/vector-service && celery -A celery_app worker -Q ml.embed --pool=solo --loglevel=info --hostname=vector@%h -O fair --without-mingle"]
    environment:
      - PYTHONPATH=/app
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_USER=ml
      - RABBITMQ_PASS=ml_password
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=bookmarkai
      - POSTGRES_PASSWORD=bookmarkai_password
      - POSTGRES_DB=bookmarkai_dev
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://tempo:4318
      - LOG_LEVEL=INFO
    depends_on:
      rabbitmq:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ../python:/app
    networks:
      - bookmarkai-network
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 2G
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "sh", "-c", "ps aux | grep -v grep | grep -q 'celery.*worker.*ml.embed' && echo 'healthy' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Celery Flower for monitoring
  flower:
    image: mher/flower:2.0
    command: ["celery", "--broker=amqp://ml:ml_password@rabbitmq:5672/", "flower", "--port=5555", "--broker_api=http://ml:ml_password@rabbitmq:15672/api/", "--purge_offline_workers=60"]
    environment:
      - CELERY_BROKER_URL=amqp://ml:ml_password@rabbitmq:5672/
      - FLOWER_PORT=5555
      - FLOWER_BROKER_API=http://ml:ml_password@rabbitmq:15672/api/
      - FLOWER_UNAUTHENTICATED_API=true
    ports:
      - '5555:5555'
    depends_on:
      - rabbitmq
    networks:
      - bookmarkai-network
    restart: unless-stopped

networks:
  bookmarkai-network:
    external: true
    name: docker_default