apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: vector-worker-scaler
  namespace: bookmarkai-ml
spec:
  scaleTargetRef:
    name: vector-worker
  pollingInterval: 15  # More frequent polling for fast processing
  cooldownPeriod: 180  # 3 minutes cooldown
  idleReplicaCount: 1  # Keep 1 replica always ready
  minReplicaCount: 1
  maxReplicaCount: 20  # Higher max for batch processing
  triggers:
  - type: rabbitmq
    metadata:
      protocol: amqp
      queueName: ml.embed
      mode: QueueLength
      value: "10"  # 10 messages per replica
      activationValue: "5"
    authenticationRef:
      name: rabbitmq-trigger-auth
  # Rate-based scaling for batch processing
  - type: prometheus
    metadata:
      serverAddress: http://prometheus.bookmarkai.svc.cluster.local:9090
      metricName: celery_task_received_total
      query: |
        sum(rate(celery_task_received_total{queue="ml.embed"}[2m]))
      threshold: "1.0"  # Scale up if receiving more than 1 task/second
      activationThreshold: "0.5"
  # Batch size metric
  - type: prometheus
    metadata:
      serverAddress: http://prometheus.bookmarkai.svc.cluster.local:9090
      metricName: ml_embedding_batch_size
      query: |
        avg_over_time(ml_embedding_batch_size[2m])
      threshold: "50"  # Scale up for large batches
      activationThreshold: "10"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 180
      policies:
      - type: Percent
        value: 25  # Scale down by 25%
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 15  # Very quick scale up
      policies:
      - type: Percent
        value: 200  # Triple the replicas
        periodSeconds: 30
      - type: Pods
        value: 4    # Add up to 4 pods at once
        periodSeconds: 30