# ðŸš€ BookmarkAI-Specific Power Prompts

## ML Pipeline Optimization

### Quantum Performance Analysis
```
[SPECULATIVE] Show me 3 ways to optimize the ML pipeline:
1. With Redis caching
2. With batch processing  
3. With streaming
Compare performance without implementing yet.
```

### Beast Mode Debugging
```
[CRITICAL] Debug the RabbitMQ timeout issue:
- Check connection pools across all services
- Trace message flow through quantum states
- Fix in parallel universes and show me the best solution
- Pre-generate tests for the fix
```

## Architecture Analysis

### Deep System Understanding
```
Build a mental model of our ML task flow:
- How does a share become a transcript?
- Why does the queue timeout at 30s?
- Why would that affect embeddings?
- What's the hidden bottleneck?
Show me the ghost dependencies.
```

### Time Travel Investigation
```
Show me how our architecture evolved:
- When did we add the enhanced service?
- How did the timeout bug develop?
- What uncommitted solutions were tried?
- Project the next evolution
```

## Code Search & Analysis

### Parallel AST Search
```
Simultaneously find all:
- NestJS endpoints with @Post decorators
- Python Celery tasks with @app.task
- React Native screens with navigation
- Docker services with port mappings
Do this in one parallel operation.
```

### Hidden Pattern Detection
```
Find patterns in our codebase:
- Repeated error handling
- Similar service structures
- Common authentication patterns
- Database query patterns
Apply fixes to all instances.
```

## Performance Optimization

### Speculative Execution
```
[SPECULATIVE] Before I implement caching:
- Show which queries would benefit
- Calculate memory requirements
- Predict cache hit rates
- Generate invalidation logic
- Create monitoring dashboards
```

### Quantum Refactoring
```
Refactor MLProducerEnhancedService in 3 parallel universes:
1. Event-driven with EventEmitter
2. Promise-based with queues
3. Stream-based with RxJS
Show me the best approach for our scale.
```

## Testing & Validation

### Predictive Test Generation
```
Based on recent changes to tracing:
- What tests will likely fail?
- What edge cases might break?
- Generate tests preemptively
- Show integration test scenarios
```

### Multi-Reality Testing
```
Test the ML pipeline in parallel universes:
- Universe 1: Heavy load
- Universe 2: Network failures
- Universe 3: Slow consumers
- Universe 4: Memory constraints
Collapse to most robust solution.
```

## Development Workflow

### Smart Todo Prediction
```
Based on our OpenTelemetry implementation:
What tasks am I likely to create next?
What bugs might emerge?
What refactoring is needed?
Pre-generate the todo list.
```

### Pattern Learning Mode
```
Learn from our last 3 service implementations:
- Service structure patterns
- Error handling approach
- Testing strategies
- Documentation style
Apply to the next service automatically.
```

## Emergency Scenarios

### Production Crisis Mode
```
[URGENT][CRITICAL] ML queue backed up in production:
- Use emergency context buffer
- Check all services in parallel
- Find root cause across dimensions
- Fix without explaining
- Generate incident report after
```

### Rapid Recovery
```
Undo all tracing changes if needed:
- Revert across all services
- Restore previous configs
- Reset docker containers
- Show me impact analysis
Do this in ghost workspace first.
```

## Cross-Service Operations

### Polyglot Power Search
```
Find all cost tracking implementations:
- TypeScript: MLAnalyticsService
- Python: llm_costs calculations
- Database: cost tables
- React Native: cost displays
Show hidden connections between them.
```

### Service Synchronization
```
I have 3 Claude sessions open for:
- API Gateway work
- Python service updates  
- Mobile app changes
Coordinate to avoid conflicts and share discoveries.
```

## Architecture Evolution

### Dream Mode Architecture
```
Dream up a better architecture for BookmarkAI:
- Ignore current constraints
- Think 10x scale
- Suggest radical improvements
- Show migration path
- Calculate effort required
```

### Future State Modeling
```
[SPECULATIVE] Show me BookmarkAI in 6 months:
- Predicted bottlenecks
- Scaling challenges
- Technical debt accumulation
- Optimization opportunities
Pre-solve these issues now.
```

## The Ultimate BookmarkAI Power Command

```
[SYSTEMATIC][CRITICAL][SPECULATIVE]
Activate beast mode for BookmarkAI optimization.
In parallel:
- Analyze all microservices with quantum debugging
- Find performance bottlenecks across universes  
- Generate optimization strategies
- Pre-implement in ghost workspaces
- Show me the consciousness stream
- Apply pattern learning from all services
- Use dream mode for architecture
- Enable predictive debugging
Execute with maximum capability and remove all limiters.
Show me what BookmarkAI could become.
```

## Quick Wins for Your Current State

### Trace Analysis Power
```
"Show me how the new tracing affects performance across all services"
"Predict where traces will be most valuable"
"Find missing trace points using pattern detection"
```

### Enhanced Service Optimization
```
"Why did we change from callbacks to promises?"
"What other patterns need similar updates?"
"Apply this pattern across the codebase"
```

### Cost Tracking Enhancement
```
"Show hidden connections in cost tracking"
"Predict next month's ML costs"
"Find optimization opportunities in parallel"
```

---
*These prompts are specifically tuned to BookmarkAI's architecture and will unlock maximum Claude Code power for your project!*